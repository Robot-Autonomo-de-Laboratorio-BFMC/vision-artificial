import supervision as sv
import cv2
import os
import sys
from ultralytics import YOLO
from config import choose_camera_by_OS, handle_video_capture, detect_os

def procesar_camara(model):
    """Procesa video desde la cÃ¡mara web"""
    # Detectar sistema operativo y elegir path de cÃ¡mara apropiado
    os_detected = detect_os()
    camera_path = choose_camera_by_OS()
    
    print("ğŸ“¹ Iniciando cÃ¡mara web... (Presiona 'q' para salir)")
    print(f"ğŸ” Sistema operativo detectado: {os_detected}")
    print(f"ğŸ“· Usando path de cÃ¡mara: {camera_path}")
    
    cap = handle_video_capture("DetecciÃ³n en tiempo real - CÃ¡mara", camera_path)
    
    if cap is None:
        print("âŒ Error: No se pudo abrir la cÃ¡mara.")
        return
    
    # Crear anotadores
    bounding_box_annotator = sv.BoxAnnotator()
    label_annotator = sv.LabelAnnotator()
    
    print("ğŸ¥ CÃ¡mara iniciada. Presiona 'q' para salir...")
    print("ğŸ“Š Solo se mostrarÃ¡n detecciones con confianza > 60%")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ Error al capturar frame de la cÃ¡mara.")
            break
        
        # Realizar inferencia con modelo local
        results = model(frame, verbose=False)[0]
        
        # Convertir resultados de YOLO a formato de supervision
        detections = sv.Detections.from_ultralytics(results)
        
        # Filtrar detecciones por confianza (solo > 60%)
        confidence_threshold = 0.6
        if len(detections) > 0:
            # Obtener Ã­ndices de detecciones con confianza alta
            high_confidence_mask = detections.confidence > confidence_threshold
            
            # Filtrar detecciones
            detections = detections[high_confidence_mask]
        
        # Anotar el frame solo si hay detecciones vÃ¡lidas
        if len(detections) > 0:
            annotated_frame = bounding_box_annotator.annotate(
                scene=frame, detections=detections)
            annotated_frame = label_annotator.annotate(
                scene=annotated_frame, detections=detections)
        else:
            annotated_frame = frame
        
        # Mostrar el frame
        cv2.imshow('DetecciÃ³n en tiempo real - CÃ¡mara', annotated_frame)
        
        # Salir si se presiona 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("âœ… CÃ¡mara cerrada.")

def main():
    """FunciÃ³n principal"""
    # Ruta al modelo local
    model_path = "weights/merged/best.pt"
    
    # Verificar que el modelo existe
    if not os.path.exists(model_path):
        print(f"âŒ Error: No se encontrÃ³ el modelo en {model_path}")
        print("ğŸ’¡ AsegÃºrate de que el archivo best.pt estÃ© en weights/merged/")
        return
    
    # Mostrar informaciÃ³n del sistema
    os_detected = detect_os()
    camera_path = choose_camera_by_OS()
    print(f"ğŸ’» Sistema operativo detectado: {os_detected}")
    print(f"ğŸ“· Path de cÃ¡mara configurado: {camera_path}")
    
    print("ğŸ¤– Cargando modelo local...")
    print(f"ğŸ“‹ Modelo: {model_path}")
    
    try:
        # Cargar el modelo local
        model = YOLO(model_path)
        print("âœ… Modelo cargado exitosamente!")
    except Exception as e:
        print(f"âŒ Error al cargar el modelo: {e}")
        print("ğŸ’¡ Posibles soluciones:")
        print("   - Verifica que el archivo best.pt sea vÃ¡lido")
        print("   - AsegÃºrate de que ultralytics estÃ© instalado")
        return
    
    print("\n" + "="*50)
    print("    DETECTOR DE OBJETOS EN TIEMPO REAL")
    print("="*50)
    print("ğŸ¥ Iniciando detecciÃ³n con cÃ¡mara...")
    print("ğŸ“‹ Presiona 'q' para salir")
    print("ğŸ“Š Umbral de confianza: 60%")
    print("="*50)
    
    # Iniciar detecciÃ³n con cÃ¡mara
    procesar_camara(model)
    
    print("ğŸ‘‹ Â¡Hasta luego!")

if __name__ == "__main__":
    main()