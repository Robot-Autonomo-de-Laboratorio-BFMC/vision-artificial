import supervision as sv
import cv2
import os
import torch
from ultralytics import YOLO
from config import choose_camera_by_OS, handle_video_capture, detect_os

def detectar_y_configurar_gpu():
    """Detecta automÃ¡ticamente si hay GPU disponible y la configura"""
    
    # DiagnÃ³stico completo de PyTorch y CUDA
    print("ğŸ” DIAGNÃ“STICO DE PYTORCH Y CUDA:")
    print(f"   PyTorch versiÃ³n: {torch.__version__}")
    print(f"   CUDA disponible: {torch.cuda.is_available()}")
    print(f"   CUDA versiÃ³n compilada: {torch.version.cuda}")
    print(f"   cuDNN versiÃ³n: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'No disponible'}")
    
    # Verificar si estamos en Jetson
    try:
        with open('/etc/nv_tegra_release', 'r') as f:
            jetson_info = f.read().strip()
            print(f"   Jetson detectado: {jetson_info}")
    except FileNotFoundError:
        print("   No es un dispositivo Jetson")
    
    # Verificar drivers NVIDIA
    try:
        import subprocess
        nvidia_smi = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
        if nvidia_smi.returncode == 0:
            print("   nvidia-smi: âœ… Disponible")
        else:
            print("   nvidia-smi: âŒ No disponible")
    except:
        print("   nvidia-smi: âŒ No disponible")
    
    print("-" * 50)
    
    if torch.cuda.is_available():
        # Configurar GPU
        device = "cuda"
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        print(f"ğŸ® GPU detectada: {gpu_name}")
        print(f"ğŸ® Memoria GPU: {gpu_memory:.1f} GB")
        print("âš¡ Usando GPU para aceleraciÃ³n")
        
        # Optimizaciones para GPU
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        return device, True
    else:
        print("ğŸ’» GPU no disponible, usando CPU")
        return "cpu", False

def procesar_camara(model, device, use_gpu):
    """Procesa video desde la cÃ¡mara web"""
    # Detectar sistema operativo y elegir path de cÃ¡mara apropiado
    os_detected = detect_os()
    camera_path = choose_camera_by_OS()
    
    print("ğŸ“¹ Iniciando cÃ¡mara web... (Presiona 'q' para salir)")
    print(f"ğŸ” Sistema operativo detectado: {os_detected}")
    print(f"ğŸ“· Usando path de cÃ¡mara: {camera_path}")
    print(f"ğŸš€ Dispositivo de inferencia: {device}")
    
    cap = handle_video_capture("DetecciÃ³n en tiempo real - CÃ¡mara", camera_path)
    
    if cap is None:
        print("âŒ Error: No se pudo abrir la cÃ¡mara.")
        return
    
    # Crear anotadores
    bounding_box_annotator = sv.BoxAnnotator()
    label_annotator = sv.LabelAnnotator()
    
    print("ğŸ¥ CÃ¡mara iniciada. Presiona 'q' para salir...")
    print("ğŸ“Š Solo se mostrarÃ¡n detecciones con confianza > 60%")
    
    # Contador de FPS
    frame_count = 0
    start_time = cv2.getTickCount()
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ Error al capturar frame de la cÃ¡mara.")
            break
        
        # Realizar inferencia con modelo local (usando GPU si estÃ¡ disponible)
        results = model(frame, verbose=False, device=device)[0]
        
        # Convertir resultados de YOLO a formato de supervision
        detections = sv.Detections.from_ultralytics(results)
        
        # Filtrar detecciones por confianza (solo > 60%)
        confidence_threshold = 0.6
        if len(detections) > 0:
            # Obtener Ã­ndices de detecciones con confianza alta
            high_confidence_mask = detections.confidence > confidence_threshold
            
            # Filtrar detecciones
            detections = detections[high_confidence_mask]
        
        # Calcular FPS
        frame_count += 1
        if frame_count % 30 == 0:  # Actualizar FPS cada 30 frames
            current_time = cv2.getTickCount()
            fps = 30 * cv2.getTickFrequency() / (current_time - start_time)
            start_time = current_time
            print(f"ğŸ“Š FPS: {fps:.1f}")
        
        # Anotar el frame solo si hay detecciones vÃ¡lidas
        if len(detections) > 0:
            annotated_frame = bounding_box_annotator.annotate(
                scene=frame, detections=detections)
            annotated_frame = label_annotator.annotate(
                scene=annotated_frame, detections=detections)
        else:
            annotated_frame = frame
        
        # Mostrar el frame
        cv2.imshow('DetecciÃ³n en tiempo real - CÃ¡mara', annotated_frame)
        
        # Salir si se presiona 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("âœ… CÃ¡mara cerrada.")

def main():
    """FunciÃ³n principal"""
    # Ruta al modelo local
    model_path = "weights/merged/best.pt"
    
    # Verificar que el modelo existe
    if not os.path.exists(model_path):
        print(f"âŒ Error: No se encontrÃ³ el modelo en {model_path}")
        print("ğŸ’¡ AsegÃºrate de que el archivo best.pt estÃ© en weights/merged/")
        return
    
    # Mostrar informaciÃ³n del sistema
    os_detected = detect_os()
    camera_path = choose_camera_by_OS()
    print(f"ğŸ’» Sistema operativo detectado: {os_detected}")
    print(f"ğŸ“· Path de cÃ¡mara configurado: {camera_path}")
    
    # Detectar y configurar GPU automÃ¡ticamente
    device, use_gpu = detectar_y_configurar_gpu()
    
    print("ğŸ¤– Cargando modelo local...")
    print(f"ğŸ“‹ Modelo: {model_path}")
    
    try:
        # Cargar el modelo local
        model = YOLO(model_path)
        print("âœ… Modelo cargado exitosamente!")
        
        # Si hay GPU, mover el modelo a GPU
        if use_gpu:
            model.to(device)
            print("ğŸš€ Modelo movido a GPU")
            
    except Exception as e:
        print(f"âŒ Error al cargar el modelo: {e}")
        print("ğŸ’¡ Posibles soluciones:")
        print("   - Verifica que el archivo best.pt sea vÃ¡lido")
        print("   - AsegÃºrate de que ultralytics estÃ© instalado")
        if use_gpu:
            print("   - Si hay problemas con GPU, instala PyTorch con soporte CUDA")
        return
    
    print("\n" + "="*50)
    print("    DETECTOR DE OBJETOS EN TIEMPO REAL")
    print("="*50)
    print("ğŸ¥ Iniciando detecciÃ³n con cÃ¡mara...")
    print("ğŸ“‹ Presiona 'q' para salir")
    print("ğŸ“Š Umbral de confianza: 60%")
    if use_gpu:
        print("âš¡ AceleraciÃ³n GPU activada")
    print("="*50)
    
    # Iniciar detecciÃ³n con cÃ¡mara
    procesar_camara(model, device, use_gpu)
    
    print("ğŸ‘‹ Â¡Hasta luego!")

if __name__ == "__main__":
    main()